{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wfdb\n",
    "from wfdb import processing\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing NSRDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "records_nsr = []\n",
    "properties_nsr = []\n",
    "annot_nsr = []\n",
    "AnnSymb_nsr = []\n",
    "AnnSamp_nsr = []\n",
    "AnnRhythm_nsr = []\n",
    "new_records_nsr = []\n",
    "AnnSamp_250_nsr = []\n",
    "\n",
    "for f in glob.glob('/data/nsrdb/*.dat'):             #### change the path to your own directory.\n",
    "    sig, fields = wfdb.rdsamp(f[:-4], channels=[1])  #### In this function, you have the opportunity to pass \"channels=[0]\" or \"channels=[1]\" to select channel 1 or 2.\n",
    "    \n",
    "    ann = wfdb.rdann(f[:-4], 'atr')\n",
    "    Symb = pd.Series(ann.symbol)\n",
    "    Samp = pd.Series(ann.sample)\n",
    "\n",
    "    Rhythm = pd.Series(ann.aux_note)\n",
    "    records_nsr.append(sig)\n",
    "    properties_nsr.append(fields)\n",
    "    annot_nsr.append(ann)\n",
    "    AnnSymb_nsr.append(Symb)\n",
    "    AnnSamp_nsr.append(Samp)\n",
    "\n",
    "    AnnRhythm_nsr.append(Rhythm)\n",
    "    \n",
    "AnnSymb_nsr = pd.Series(AnnSymb_nsr).values\n",
    "AnnSamp_nsr = pd.Series(AnnSamp_nsr).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_Rpeaks_nsr.rename(columns={0: 'Rpeaks'},\n",
    "          inplace=True, errors='raise')\n",
    "labeled_Rpeaks_nsr['Label'] = 0\n",
    "\n",
    "Rpeaks_nsr = labeled_Rpeaks_nsr[\"Rpeaks\"]\n",
    "Label_nsr = labeled_Rpeaks_nsr[\"Label\"]\n",
    "Label_nsr = np.array(Label_nsr, dtype=np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rescaling frequency sampling of 128 Hz for LTAFDB into 250 Hz (AFDB) and preprocess the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labeled_Rpeaks_nsr = []\n",
    "appended_data_nsr = []\n",
    "for i in range(18): ## 18 records\n",
    "    df = pd.DataFrame(AnnSamp_nsr[i]*2) ### Roughly resampling from 128 to 250 Hz\n",
    "    appended_data_nsr.append(df)\n",
    "\n",
    "labeled_Rpeaks_nsr = pd.concat(appended_data_nsr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ECG records segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmenting_record_nsr(seg_value_nsr):\n",
    "    rri2_nsr = np.diff(Rpeaks_nsr) ### Storing the intervals between rpeaks\n",
    "    rri2_nsr = np.array(rri2_nsr, dtype=np.float64) ### Ensuring no overflow issues happens, when calculating in for loop later\n",
    "    \n",
    "    amount_nsr = -(len(rri2_nsr) % seg_value_nsr) # amount of data points to remove, for equal length segments with no residue points\n",
    "    print(f\"Amount to remove {amount_nsr}\")\n",
    "    \n",
    "    rec_amount_nsr = rri2_nsr[:amount_nsr]\n",
    "    seg_shape_nsr = len(rec_amount_nsr) // seg_value_nsr # amount of total segments (given the specified segment length) \n",
    "    print(f\"Shape 0: {seg_shape_nsr}\")\n",
    "    \n",
    "    segmented_rec_nsr = rec_amount_nsr.reshape(seg_shape_nsr,seg_value_nsr)\n",
    "    return segmented_rec_nsr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting and segmenting the input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loads in functions for Shannon Entropy, Mean absolute deviation calculations\n",
    "%run \"features_utils.ipynb\"\n",
    "from scipy.stats import median_abs_deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_len = 20\n",
    "segmented_record_nsr, amount_nsr, seg_shape_nsr = segmenting_record_nsr(seg_len) # Specify the segment length\n",
    "\n",
    "all_features_nsr = []\n",
    "\n",
    "### Calculating features for every single segmented \"block\" inside the segmented_record_nsr variable\n",
    "for x in range(len(segmented_record_nsr)):\n",
    "    \n",
    "    #MEAN\n",
    "    ff1 = np.nanmean(segmented_record_nsr[x]) ### nanmean, nanstd computes values while ignoring nan-values\n",
    "    #STD\n",
    "    ff2 = np.nanstd(segmented_record_nsr[x])\n",
    "    #RMSSD\n",
    "    sum_ = 0\n",
    "    for y in range(len(segmented_record_nsr[x]) - 1): ### loops 19 times\n",
    "        sum_ += (segmented_record_nsr[x][y] - segmented_record_nsr[x][y+1])**2\n",
    "    sum_multiplied = 1/(len(segmented_record_nsr) - 1) * sum_\n",
    "    ff3 = np.sqrt(sum_multiplied)\n",
    "    #NORMALIZED RMSSD\n",
    "    ff4 = (ff3 / ff1)\n",
    "    #SHANNON ENTROPY\n",
    "    ff5 = entropy(segmented_record_nsr[x])\n",
    "    #MEAN ABSOLUTE DEVIATION\n",
    "    ff6 = mean_abs_deviation(segmented_record_nsr[x])\n",
    "    #MEDIAN ABSOLUTE DEVIATION\n",
    "    ff7 = median_abs_deviation(segmented_record_nsr[x])\n",
    "\n",
    "    my_features = pd.Series([np.around(ff1, 3), np.around(ff2, 3), np.around(ff3, 3), np.around(ff4, 3), np.around(ff5, 3), \n",
    "                             np.around(ff6, 3), np.around(ff7, 3)],\n",
    "                            index=['Mean','STD','RMSSD','Normalized RMSSD','Shannon Entropy',\n",
    "                                   'Mean absolute deviation','Median absolute deiviation'])\n",
    "    all_features_nsr.append(my_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the rhythms' labels/targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_amount_nsr = Label_nsr[:amount_nsr-1] \n",
    "y_shape_nsr = y_amount_nsr.reshape(seg_shape_nsr, seg_len) \n",
    "y_list_nsr = []\n",
    "\n",
    "### Calc if every 20 segment block is Normal synus rythm or AFIB\n",
    "for g in range(len(y_shape_nsr)):\n",
    "    #y_segment = y_shape\n",
    "    sum_segment_nsr = np.sum(y_shape_nsr[g])\n",
    "    if sum_segment_nsr >= int(seg_len/2): \n",
    "        sum_segment_nsr = 1\n",
    "    else: sum_segment_nsr = 0\n",
    "    y_list_nsr.append(sum_segment_nsr)\n",
    "\n",
    "y_list_nsr = np.array(y_list_nsr, dtype=np.float64)\n",
    "print(y_list_nsr.dtype)\n",
    "print(f\"Length of y_list: {len(y_list_nsr)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
